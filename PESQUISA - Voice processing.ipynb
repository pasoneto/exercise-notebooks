{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code to take TON files that have been checked, and export pitch information (Hz, MIDI), note information, and a plot of note information\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bz2\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import collections  as mc\n",
    "is_non_decimal = re.compile(r\"[^\\d.]+\")\n",
    "\n",
    "dir_needs_check = '/Users/Lenovo/Desktop/estudo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "renditionList\n",
    "\n",
    "Function to return a list of files in dir 'dirLookup' that end with string\n",
    "'endsWith'.\n",
    "\n",
    "Checks to make sure that other necessary files exist.\n",
    "\n",
    "For now, skips files that already have been processed, meaning there's an \n",
    "output file for that rendition that ends with 'skipIfYouSeeThisOutput'\n",
    "\"\"\"\n",
    "#Function to find the files. Change it to find different formats of files.\n",
    "def renditionList(dirLookup,\n",
    "                  endsWith='.ton',\n",
    "                  skipIfYouSeeThisOutput=''):\n",
    "\n",
    "    os.chdir(dirLookup)\n",
    "    \n",
    "    listdirectory = os.listdir(\"/\")\n",
    "    \n",
    "    renditions = []\n",
    "    for filename in listdirectory: \n",
    "        \n",
    "        if filename.endswith(endsWith):\n",
    "            \n",
    "            # don't add to list if output file exists already\n",
    "            skipIfSeen = dirLookup + filename[0:-len(endsWith)] + skipIfYouSeeThisOutput\n",
    "            \n",
    "            if os.path.isfile(skipIfSeen)==0:\n",
    "                renditions.append(filename[0:-len(endsWith)])\n",
    "                \n",
    "    return renditions;\n",
    "\n",
    "def ton_to_onsets(full_filepath):\n",
    "\n",
    "    import bz2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "#Opens up a file, reads it, decodes it into utf strips off white space and splits\n",
    "    content = bz2.BZ2File(full_filepath).read().decode(\"utf-8\").rstrip().split(\"\\n\")\n",
    "\n",
    "    onset_frame = []\n",
    "    duration_frames = []\n",
    "    central_tendency_freq = []\n",
    "    for somestring in content:\n",
    "        if (\n",
    "            \"point frame\" in somestring\n",
    "            and \"value\" in somestring\n",
    "            and \"label\" in somestring\n",
    "            and \"duration\" in somestring\n",
    "        ):\n",
    "            to_parse = somestring.split(\" \")\n",
    "            for x in to_parse:\n",
    "                if \"frame\" in x:\n",
    "                    val = int(is_non_decimal.sub(\"\", x))\n",
    "                    onset_frame.append(val)\n",
    "                if \"duration\" in x:\n",
    "                    val2 = int(is_non_decimal.sub(\"\", x))\n",
    "                    duration_frames.append(val2)\n",
    "                if \"value\" in x:\n",
    "                    val3 = is_non_decimal.sub(\"\", x)\n",
    "                    central_tendency_freq.append(val3)\n",
    "#Sample rate. Reframes from different time samples.\n",
    "    onset_s = np.array(onset_frame).astype(float) / 44100\n",
    "    duration_s = np.array(duration_frames).astype(float) / 44100\n",
    "    central_tendency_freq = np.array(central_tendency_freq).astype(float)\n",
    "    midi = 12 * np.log2(central_tendency_freq / 440) + 69\n",
    "\n",
    "    cur_df_notes = pd.DataFrame(\n",
    "        {\n",
    "            \"Onset\": onset_s,\n",
    "            \"Duration\": duration_s,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    cur_df_notes = cur_df_notes.round(3)\n",
    "\n",
    "    return cur_df_notes;\n",
    "\n",
    "def ton_to_pitch(full_filepath):\n",
    "    \n",
    "    import bz2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    content = bz2.BZ2File(f_fullpath).read().decode(\"utf-8\").rstrip().split(\"\\n\")\n",
    "\n",
    "    frame_subset = []\n",
    "    pitch_subset = []\n",
    "    for somestring in content:\n",
    "        if (\n",
    "            \"point frame\" in somestring\n",
    "            and \"value\" in somestring\n",
    "            and \"label\" in somestring\n",
    "            and \"duration\" not in somestring\n",
    "        ):\n",
    "            to_parse = somestring.split(\" \")\n",
    "            for x in to_parse:\n",
    "                if \"frame\" in x:\n",
    "                    val = int(is_non_decimal.sub(\"\", x))\n",
    "                    frame_subset.append(val)\n",
    "                if \"value\" in x:\n",
    "                    val2 = float(is_non_decimal.sub(\"\", x))\n",
    "                    pitch_subset.append(val2)\n",
    "\n",
    "    # calculate the final frame of the annotations \n",
    "    # (pitch track must extend that far)\n",
    "    onset_frame = []\n",
    "    duration_frames = []\n",
    "    for somestring in content:\n",
    "        if (\n",
    "            \"point frame\" in somestring\n",
    "            and \"value\" in somestring\n",
    "            and \"label\" in somestring\n",
    "            and \"duration\" in somestring\n",
    "        ):\n",
    "            to_parse = somestring.split(\" \")\n",
    "            for x in to_parse:\n",
    "                if \"frame\" in x:\n",
    "                    val = int(is_non_decimal.sub(\"\", x))\n",
    "                    onset_frame.append(val)\n",
    "                if \"duration\" in x:\n",
    "                    val2 = int(is_non_decimal.sub(\"\", x))\n",
    "                    duration_frames.append(val2)\n",
    "    final_frame_anno = np.max(np.array(onset_frame) + np.array(duration_frames))\n",
    "    if max(frame_subset) > final_frame_anno:\n",
    "        max_frame = max(frame_subset)\n",
    "    else:\n",
    "        max_frame = final_frame_anno\n",
    "\n",
    "    # turn sparse format pitch information to continuous pitch information\n",
    "    # uses steps of 256 (chunks of samples, default in TONY)\n",
    "    pitch_expand = []\n",
    "    for i in range(0, max_frame, 256):\n",
    "        if i in frame_subset:\n",
    "            idx = frame_subset.index(i)\n",
    "            if pitch_subset[idx]==0:\n",
    "                pitch_expand.append(np.nan)\n",
    "            else:\n",
    "                pitch_expand.append(pitch_subset[idx])\n",
    "        else:\n",
    "            pitch_expand.append(np.nan)\n",
    "    frame_expand = np.arange(0, max_frame, 256)\n",
    "    pitch_expand = np.asarray(pitch_expand)\n",
    "\n",
    "    # place continuous pitch info into dataframe\n",
    "    cur_pitch_track = []\n",
    "    cur_pitch_track = pd.DataFrame(\n",
    "        {\n",
    "            \"Time\": frame_expand / 44100,\n",
    "            \"Hz\": pitch_expand,\n",
    "            \"MIDI\": 12 * np.log2(pitch_expand / 440) + 69,\n",
    "        }\n",
    "    )\n",
    "    cur_pitch_track = cur_pitch_track.round(3)\n",
    "\n",
    "    return cur_pitch_track;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_note_info(onsets_durs,Hz_track):\n",
    "   \n",
    "    # loop through each note and calculate measures of interest\n",
    "    count=0\n",
    "    note_num = []\n",
    "    prop_note_ok = []\n",
    "    cur_note_med_Hz = []\n",
    "    cur_note_med_MIDI = []\n",
    "    cur_note_iqtl_range_MIDI = []\n",
    "    note_onset = []\n",
    "    note_length = []\n",
    "    note_middle_length = []\n",
    "    \n",
    "    for index, row in onsets_durs.iterrows():\n",
    "\n",
    "        # the onset/offset in seconds\n",
    "        onset_s = row[\"Onset\"].astype(float)\n",
    "        offset_s = row[\"Onset\"].astype(float) + row[\"Duration\"].astype(float)\n",
    "     \n",
    "        # find the indices of the note in the Hz track\n",
    "        # roundabout but works if the time values are slightly different\n",
    "        nearest_time_onset = np.abs(Hz_track[\"Time\"] - onset_s)\n",
    "        nearest_time_offset = np.abs(Hz_track[\"Time\"] - offset_s)\n",
    "        idx_on = np.where(Hz_track.Time == Hz_track[\"Time\"][nearest_time_onset.idxmin])[0]\n",
    "        idx_off = np.where(Hz_track.Time == Hz_track[\"Time\"][nearest_time_offset.idxmin])[0]\n",
    "        \n",
    "        # consider middle section of note only (interquartile [iqtl] range 25-75)\n",
    "        note_quartile_in_idxs = np.ceil((idx_off - idx_on)/4).astype(int)\n",
    "        idx_on = idx_on + note_quartile_in_idxs\n",
    "        idx_off = idx_off - note_quartile_in_idxs\n",
    "        \n",
    "        # pull out the freq values for stats\n",
    "        cur_note_cont_Hz = Hz_track[\"Hz\"][int(idx_on):int(idx_off)]\n",
    "\n",
    "        # pull out the MIDI values for stats\n",
    "        cur_note_cont_MIDI = 12 * np.log2(cur_note_cont_Hz / 440) + 69\n",
    "\n",
    "        # what proportion of the note has valid values?\n",
    "        prop_valid = 1 - sum(np.isnan(cur_note_cont_Hz)) / len(cur_note_cont_Hz)\n",
    "        \n",
    "        if prop_valid > 0:\n",
    "            # calculate the measures of interest for this note\n",
    "            count = count + 1\n",
    "            note_num.append(count)\n",
    "            note_onset.append(row[\"Onset\"].astype(float))\n",
    "            note_length.append(row[\"Duration\"].astype(float))\n",
    "            note_middle_length.append(Hz_track.Time[idx_off].values[0] - Hz_track.Time[idx_on].values[0])\n",
    "            prop_note_ok.append(prop_valid)        \n",
    "            cur_note_med_Hz.append(np.nanmedian(cur_note_cont_Hz))\n",
    "            cur_note_med_MIDI.append(np.nanmedian(cur_note_cont_MIDI))\n",
    "            \n",
    "            q75, q25 = np.percentile(cur_note_cont_MIDI, [75 ,25])\n",
    "            iqr = q75 - q25\n",
    "            cur_note_iqtl_range_MIDI.append(iqr)   \n",
    "\n",
    "    note_info = pd.DataFrame(\n",
    "        dict(\n",
    "            {\n",
    "                \"note_num\": note_num,\n",
    "                \"prop_note_ok\": prop_note_ok,\n",
    "                \"iqtl_median_Hz\": cur_note_med_Hz,\n",
    "                \"iqtl_median_midi\": cur_note_med_MIDI,\n",
    "                \"iqtl_range\": cur_note_iqtl_range_MIDI,\n",
    "                \"note_onset\": note_onset,\n",
    "                \"note_length\": note_length,\n",
    "                \"iqtl_note_length\": note_middle_length,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # get the intervals (since n-1, first entry is NA to align with notes in same table)\n",
    "    note_info['interval_semitones'] = np.insert(np.array(note_info['iqtl_median_midi'][1:]) - \n",
    "                                      np.array(note_info['iqtl_median_midi'][0:-1]).astype(float), \n",
    "                                      0, \n",
    "                                      np.nan, \n",
    "                                      axis=0)\n",
    "    \n",
    "    note_info = note_info.round(2)\n",
    "    \n",
    "    return note_info;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_annotation(onsets_durs,Hz_track,note_info,filename):\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = plt.axes()\n",
    "\n",
    "    plt.title(f)\n",
    "    plt.xlabel('Recording time (s)')\n",
    "    plt.ylabel('MIDI note number (Middle C = 60)')\n",
    "\n",
    "    ax.plot(Hz_track['Time'], Hz_track['MIDI'],'r')\n",
    "\n",
    "    for i in range(0,len(note_info)):\n",
    "        x_0 = note_info['note_onset'][i]\n",
    "        x_100 = (note_info['note_onset'][i]+note_info['note_length'][i])\n",
    "        x_width = (x_100 - x_0)\n",
    "        x_50 = x_0 + x_width/2\n",
    "        y1 = note_info['iqtl_median_midi'][i] - 0.5\n",
    "        y2 = note_info['iqtl_median_midi'][i] + 0.5\n",
    "\n",
    "        ax.plot([x_0,x_0],[y1,y2], color = 'k', linewidth=2)\n",
    "        ax.plot([x_100,x_100],[y1,y2], color = 'k', linewidth=2)\n",
    "        ax.text(x_0,y2+0.2,str(i+1),ha='center')\n",
    "\n",
    "        iqr = note_info['iqtl_range'][i]\n",
    "        y1_iqr = note_info['iqtl_median_midi'][i] - iqr*0.5\n",
    "        y2_iqr = note_info['iqtl_median_midi'][i] + iqr*0.5\n",
    "        if iqr < 1:\n",
    "            ax.add_patch(patches.Rectangle((x_0, y1_iqr),x_width,y2_iqr-y1_iqr,linewidth=1,color='#bddfeb',zorder=0.5))\n",
    "        else:\n",
    "            ax.add_patch(patches.Rectangle((x_0, y1_iqr),x_width,y2_iqr-y1_iqr,linewidth=1,color='y',zorder=0.5))\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        def applyPlotStyle():\n",
    "            med_f0 = note_info['iqtl_median_midi']\n",
    "            plt.yticks(np.arange(np.nanmin(np.floor(med_f0))-2, np.nanmax(np.ceil(med_f0))+2, step=1))\n",
    "            plt.ylim(np.nanmin(np.floor(med_f0))-2, np.nanmax(np.ceil(med_f0))+2)\n",
    "            plt.grid(b=1, which='major', axis='y')\n",
    "\n",
    "        applyPlotStyle()\n",
    "\n",
    "        ax.scatter(x_50, note_info['iqtl_median_midi'][i],color = 'k',s=100)\n",
    "\n",
    "    plt.tight_layout()    \n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of folders to check\n",
    "os.chdir(dir_needs_check)\n",
    "list_folders = [f for f in os.listdir(dir_needs_check) if not f.startswith('.')]\n",
    "\n",
    "# loop through each folder (one per participant)\n",
    "for folder in list_folders:\n",
    "    \n",
    "    # get list of original TON session files in folder\n",
    "    os.chdir(dir_needs_check + '/' + folder)\n",
    "    list_files = os.listdir(\".\")\n",
    "    list_TON = []\n",
    "    for filename in list_files: \n",
    "        if filename.endswith(\"_checked.ton\"):\n",
    "            list_TON.append(filename)\n",
    "\n",
    "    # loop through files\n",
    "    for f in list_TON:\n",
    "\n",
    "        # open up the onset/duration information from TON file\n",
    "        f_fullpath = dir_needs_check + '/' + folder + '/' + f\n",
    "        onsets_durs = ton_to_onsets(f_fullpath)\n",
    "\n",
    "        # only keep notes that exceed a minimum duration\n",
    "        minimum_note_duration = 0.05\n",
    "        onsets_durs = onsets_durs[onsets_durs.Duration > minimum_note_duration]\n",
    "\n",
    "        # save onset/duration info to disk\n",
    "        onsets_durs.to_csv(f[0:-12] + '_notebounds.csv', index=False)\n",
    "\n",
    "        # get continuous pitch information from TON file\n",
    "        f_fullpath = dir_needs_check + '/' + folder + '/' + f\n",
    "        Hz_track = ton_to_pitch(f_fullpath)\n",
    "\n",
    "        # save pitch track to disk\n",
    "        Hz_track.to_csv(f[0:-12] + '_pitchtrack.csv', index=False)\n",
    "\n",
    "        # calculate note info (median pitch / duration / etc)\n",
    "        note_info = calc_note_info(onsets_durs,Hz_track)\n",
    "\n",
    "        # add the participant's ID\n",
    "        note_info['participant'] = np.tile(str.split(f,'_')[0],len(note_info))\n",
    "\n",
    "        # add the trial ID\n",
    "        note_info['trial'] = np.tile(str.split(f,'_')[1],len(note_info))\n",
    "\n",
    "        # reorder the columns\n",
    "        note_info = note_info[\n",
    "            [\n",
    "            'participant', \n",
    "            'trial',\n",
    "            'note_num', \n",
    "            'prop_note_ok', \n",
    "            'iqtl_median_Hz', \n",
    "            'iqtl_median_midi', \n",
    "            'iqtl_range', \n",
    "            'note_onset',\n",
    "            'note_length',\n",
    "            'iqtl_note_length',\n",
    "            'interval_semitones'\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        # save note information as CSV\n",
    "        note_info.to_csv(f[:-11]+'note_info.csv',index=False)\n",
    "        \n",
    "        # visualize the annotation\n",
    "        plot_annotation(onsets_durs,Hz_track,note_info,f[:-11]+'visualized.png')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
